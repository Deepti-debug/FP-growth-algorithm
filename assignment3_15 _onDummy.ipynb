{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816bfbf3",
   "metadata": {},
   "source": [
    "#### **1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97256b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                                 # Importing for panel data analysis\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np                                                  # Importing package numpys (For Numerical Python)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt                                     # Importing pyplot interface of matplotlib\n",
    "import seaborn as sns                                               # Importing seaborn library for interactive visualization\n",
    "%matplotlib inline\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "#--------------------~-----------------------------------------------------------------------------------------------------------\n",
    "import pyfpgrowth                                                   # For testing the scratch implementation\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings                                                     # Importing warning to disable runtime warnings\n",
    "warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c1ac1",
   "metadata": {},
   "source": [
    "- Divide the data set into 80% training set and 20% test set. Remove 20% of\n",
    "movies watched from each user and create a test set using the removed\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab3a8bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movies_rated_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[100, 200, 300, 400, 500, 600, 700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[100, 200, 300, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 300, 400, 500, 600, 700, 800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 400, 500, 600, 700, 800, 900, 1000, 1100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[700, 800, 900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                               movies_rated_above_2\n",
       "0       1                [100, 200, 300, 400, 500, 600, 700]\n",
       "1       2                               [100, 200, 300, 400]\n",
       "2       4                [100, 300, 400, 500, 600, 700, 800]\n",
       "3       6  [100, 400, 500, 600, 700, 800, 900, 1000, 1100...\n",
       "4       8                                    [700, 800, 900]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy data\n",
    "dummy_df = pd.DataFrame({'userId':[1,2,4,6,8], 'movies_rated_above_2':[[100,200,300,400,500,600,700], [100,200,300,400], [100,300,400,500,600,700,800], [100,400, 500,600,700,800,900,1000,1100,1200], [700,800,900]]})\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c643aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- Parse through each user\\n- Randomly shuffle the items in the list and split into 80-20\\n- extract 20 of each user and make a separate df\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing dummy df into 80-20 train-test, such that 20% of movies watched from each user is test set.\n",
    "'''\n",
    "- Parse through each user\n",
    "- Randomly shuffle the items in the list and split into 80-20\n",
    "- extract 20 of each user and make a separate df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5803c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 300, 400, 500, 600, 700]\n",
      "-----\n",
      "test_list [100, 200]\n",
      "-----\n",
      "train_list [300, 400, 500, 600, 700]\n",
      "******************************************************\n",
      "[100, 200, 300, 400]\n",
      "-----\n",
      "test_list [100]\n",
      "-----\n",
      "train_list [200, 300, 400]\n",
      "******************************************************\n",
      "[100, 300, 400, 500, 600, 700, 800]\n",
      "-----\n",
      "test_list [500, 400]\n",
      "-----\n",
      "train_list [100, 300, 600, 700, 800]\n",
      "******************************************************\n",
      "[100, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
      "-----\n",
      "test_list [100, 400]\n",
      "-----\n",
      "train_list [500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
      "******************************************************\n",
      "[700, 800, 900]\n",
      "-----\n",
      "test_list [800]\n",
      "-----\n",
      "train_list [700, 900]\n",
      "******************************************************\n"
     ]
    }
   ],
   "source": [
    "cols = ['userId', 'movies_rated_above_2']\n",
    "train_df = pd.DataFrame(columns=cols)\n",
    "test_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "# loop through the rows using iterrows()\n",
    "for index, row in dummy_df.iterrows():\n",
    "    # print(row['userId'], row['movies_rated_above_2'])\n",
    "    print(row['movies_rated_above_2'])\n",
    "    print(\"-----\")\n",
    "    n = int(np.ceil(0.2 * len(row['movies_rated_above_2'])))  # initialize a value that represents 20% of the total items in the list.\n",
    "    test_list = random.sample(row['movies_rated_above_2'], n)  # randomly choose 20% of the values (n) from list and make a sublist.\n",
    "    print(\"test_list\", test_list)\n",
    "    print(\"-----\")\n",
    "    train_list = [i for i in row['movies_rated_above_2'] if i not in test_list] # rest 80% values of list is in train/-list\n",
    "    print(\"train_list\", train_list) # randomly choose 20% of the values from list and make a sublist\n",
    "    print(\"******************************************************\")\n",
    "    \n",
    "    df_1 = pd.DataFrame({\n",
    "    'userId': [row['userId']],\n",
    "    'movies_rated_above_2': [train_list]\n",
    "    })\n",
    "\n",
    "    df_2 = pd.DataFrame({\n",
    "    'userId': [row['userId']],\n",
    "    'movies_rated_above_2': [test_list]\n",
    "    })\n",
    "\n",
    "    train_df = pd.concat([train_df, df_1])\n",
    "    test_df = pd.concat([test_df, df_2])\n",
    "    # print(\"index\", index)\n",
    "    # train_df.loc[index].userId = row['userId']\n",
    "    # train_df.loc[index].movies_rated_above_2 = train_list\n",
    "\n",
    "    # test_df.loc[index].userId = row['userId']\n",
    "    # test_df.loc[index].movies_rated_above_2 = test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2880e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movies_rated_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[100, 200, 300, 400, 500, 600, 700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[100, 200, 300, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 300, 400, 500, 600, 700, 800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 400, 500, 600, 700, 800, 900, 1000, 1100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[700, 800, 900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                               movies_rated_above_2\n",
       "0       1                [100, 200, 300, 400, 500, 600, 700]\n",
       "1       2                               [100, 200, 300, 400]\n",
       "2       4                [100, 300, 400, 500, 600, 700, 800]\n",
       "3       6  [100, 400, 500, 600, 700, 800, 900, 1000, 1100...\n",
       "4       8                                    [700, 800, 900]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "784a0f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movies_rated_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[300, 400, 500, 600, 700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[200, 300, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 300, 600, 700, 800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[500, 600, 700, 800, 900, 1000, 1100, 1200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[700, 900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId                         movies_rated_above_2\n",
       "0      1                    [300, 400, 500, 600, 700]\n",
       "0      2                              [200, 300, 400]\n",
       "0      4                    [100, 300, 600, 700, 800]\n",
       "0      6  [500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
       "0      8                                   [700, 900]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45b3982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movies_rated_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[100, 200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[500, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[100, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[800]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId movies_rated_above_2\n",
       "0      1           [100, 200]\n",
       "0      2                [100]\n",
       "0      4           [500, 400]\n",
       "0      6           [100, 400]\n",
       "0      8                [800]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10f056",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bab16a",
   "metadata": {},
   "source": [
    "#### **3. Association rule mining**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d13f5",
   "metadata": {},
   "source": [
    "- From the training set, extract the set of all association rules of form X→Y, <br />\n",
    "where X contains a single movie and Y contains the set of movies from the training set <br />\n",
    "by employing the apriori or FPgrowth approach and set some minsup and minconf (eg : 50 and 0.1 respectively) <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42523a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (5, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movies_rated_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[300, 400, 500, 600, 700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[200, 300, 400]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, 300, 600, 700, 800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[500, 600, 700, 800, 900, 1000, 1100, 1200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[700, 900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId                         movies_rated_above_2\n",
       "0      1                    [300, 400, 500, 600, 700]\n",
       "0      2                              [200, 300, 400]\n",
       "0      4                    [100, 300, 600, 700, 800]\n",
       "0      6  [500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
       "0      8                                   [700, 900]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the training transactional data\n",
    "print('Shape of the dataset:', train_df.shape)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31d72ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the type of the rows in the second column of the transactional dataframe 'train_df'\n",
    "type(train_df.movies_rated_above_2.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54b46711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 400, 500, 600, 700]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.movies_rated_above_2.iloc[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5f4e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [300, 400, 500, 600, 700],\n",
       " 2: [200, 300, 400],\n",
       " 4: [100, 300, 600, 700, 800],\n",
       " 6: [500, 600, 700, 800, 900, 1000, 1100, 1200],\n",
       " 8: [700, 900]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_key_value = dict(zip(train_df['userId'], train_df['movies_rated_above_2']))\n",
    "train_df_key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ff03e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 400, 500, 600, 700]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_key_value[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be975cb",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8fed6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque \n",
    "\n",
    "def traversetree(root):\n",
    "    queue = deque([(root, root, 0)])\n",
    "    while queue:\n",
    "        parent_node, node, level = queue.popleft()\n",
    "        print(f\"{level = }\")\n",
    "        print(f\"Parent: {parent_node.item}, Parent count: {parent_node.count}, Data: {node.item}, Count: {node.count}\")\n",
    "        for node_name in node.children:\n",
    "            queue.append((node, node.children[node_name], level + 1))\n",
    "\n",
    "def traverseheader(header_table):\n",
    "    for key in header_table.keys():\n",
    "        node = header_table[key]\n",
    "        while node is not None:\n",
    "            print(f\"Header item: {key}, Link data: {node.item}, Link count: {node.count}\")\n",
    "            node = node.link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc08e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent_patterns = [([300], 3), ([600], 3), ([600, 700], 3), ([700], 4)]\n"
     ]
    }
   ],
   "source": [
    "#Global variable\n",
    "id = 0\n",
    "class Node:\n",
    "    def __init__(self, item, count, parent):\n",
    "        self.item = item           # Item value\n",
    "        self.count = count         # Support count of the itemset\n",
    "        self.parent = parent       # Parent node\n",
    "        self.children = {}         # Children nodes (item: Node)\n",
    "        self.link = None \n",
    "\n",
    "class FPGrowth:\n",
    "    def __init__(self, data, minsup):\n",
    "        self.data = data\n",
    "\n",
    "    \n",
    "    def find_frequent_items(self,data, minsup):\n",
    "        header_table = {}\n",
    "        for _, item_ls in data.items():\n",
    "            for item in item_ls:\n",
    "                header_table[item] = header_table.get(item, 0) + 1\n",
    "        \n",
    "        #Sort the dictionary\n",
    "        # print(f\"Before sorting {header_table = }\")\n",
    "        header_table = {k: v for k, v in sorted(header_table.items(), key=lambda item: (item[1], item[0]), reverse=True)}\n",
    "        # print(f\"After sorting {header_table = }\")\n",
    "        header_table = {k:-1 for k,v in header_table.items() if v>minsup}\n",
    "        self.l = [*header_table.keys()]\n",
    "        return header_table \n",
    "    \n",
    "    #Constructing an FPTree\n",
    "    def construct_fptree(self, data, header_table):\n",
    "        root = Node(None,0,None)\n",
    "        for _, transaction in data.items():\n",
    "            ordered_transaction = [item for item in transaction if item in self.l]\n",
    "            ordered_transaction.sort(key = lambda x:self.l.index(x))\n",
    "            current_node = root\n",
    "            # print(f\"{ordered_transaction = }\")\n",
    "            for item in ordered_transaction:\n",
    "                if item in current_node.children:\n",
    "                    #Update the count of the already existing node\n",
    "                    child_node = current_node.children[item]\n",
    "                    child_node.count += 1\n",
    "                else:\n",
    "                    #Create a new node \n",
    "                    child_node = Node(item, 1, current_node)\n",
    "                    current_node.children[item] = child_node\n",
    "                    #Update header table\n",
    "                    if item in header_table: #Why does this exist?\n",
    "                        if header_table[item] == -1:\n",
    "                            header_table[item] = child_node\n",
    "                        else:\n",
    "                            header_node = header_table[item]\n",
    "                            while header_node.link is not None:\n",
    "                                header_node =  header_node.link\n",
    "                            header_node.link = child_node \n",
    "                current_node = child_node \n",
    "        return root, header_table\n",
    "\n",
    "    #Mining an FPTree\n",
    "    def mine_frequent_patterns(self, header_table, min_support, prefix=[]):\n",
    "        global id\n",
    "        frequent_patterns = []\n",
    "        # Sort items in header table in descending order of frequency\n",
    "        sorted_items = [item for item in header_table.keys()]\n",
    "        sorted_items.sort(key=lambda x: (header_table[x].count, x))\n",
    "        for item in sorted_items:\n",
    "            new_prefix = prefix + [item]\n",
    "            support = 0\n",
    "            # Build the conditional pattern base\n",
    "            conditional_dataset = {}\n",
    "            node = header_table[item]\n",
    "            while node is not None:\n",
    "                count = node.count\n",
    "                support += count \n",
    "                path = []\n",
    "                current_node = node.parent\n",
    "                while current_node.parent is not None:\n",
    "                    path.append(current_node.item)\n",
    "                    current_node = current_node.parent\n",
    "                for _ in range(count):\n",
    "                    conditional_dataset[id] = path\n",
    "                    id += 1\n",
    "                node = node.link\n",
    "            frequent_patterns.append((new_prefix, support))\n",
    " \n",
    "            \n",
    "            # Recursively mine the conditional FP-tree\n",
    "            conditional_header_table = self.find_frequent_items(conditional_dataset, min_support)\n",
    "            root, conditional_header_table = self.construct_fptree(conditional_dataset, conditional_header_table)\n",
    "            # print(f\"Conditional prefix tree for prefix: {new_prefix}\")\n",
    "            # traversetree(root)\n",
    "            # print()\n",
    "            if conditional_header_table:\n",
    "                frequent_patterns.extend(self.mine_frequent_patterns(conditional_header_table, min_support, new_prefix))\n",
    "  \n",
    "        return frequent_patterns\n",
    "        \n",
    "\n",
    "minsup = 2 # actual - 10\n",
    "FPGrowth_obj = FPGrowth(train_df_key_value, minsup)\n",
    "header_table = FPGrowth_obj.find_frequent_items(train_df_key_value,minsup)\n",
    "root, header_table = FPGrowth_obj.construct_fptree(train_df_key_value, header_table)\n",
    "frequent_patterns = FPGrowth_obj.mine_frequent_patterns(header_table, minsup, [])\n",
    "print(f\"{frequent_patterns = }\")\n",
    "#For debugging\n",
    "# traversetree(root)\n",
    "# traverseheader(header_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3d862f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patterns = {(300,): 3, (600,): 3, (600, 700): 3, (700,): 4}\n"
     ]
    }
   ],
   "source": [
    "#Testing with in-built python package\n",
    "transactions = [[300, 400, 500, 600, 700], [200, 300, 400], [100, 300, 600, 700, 800], [500, 600, 700, 800, 900, 1000, 1100, 1200], [700, 900]]\n",
    "patterns = pyfpgrowth.find_frequent_patterns(transactions, 3)\n",
    "print(f\"{patterns = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a829f",
   "metadata": {},
   "source": [
    "Cool! Frequent patterns are accurately computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca90ed",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e36b06bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  pattern 0 out of 4\n",
      "Processing  pattern 1 out of 4\n",
      "Processing  pattern 2 out of 4\n",
      "Processing  pattern 3 out of 4\n",
      "association_rules_ls = [[[600, 700], 3, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def calc_confidence(data, antecedant, consequent):\n",
    "    item_ls = [*data.values()]\n",
    "    antecedant_union_consequent = set([antecedant] + list(consequent))\n",
    "    support_antecedant = 0\n",
    "    support_antecedant_union_consequent = 0\n",
    "    for item in item_ls:\n",
    "        if set([antecedant]).issubset(set(item)):\n",
    "            support_antecedant += 1\n",
    "        if set(antecedant_union_consequent).issubset(set(item)):\n",
    "            support_antecedant_union_consequent += 1\n",
    "    conf = support_antecedant_union_consequent / support_antecedant\n",
    "    return conf  \n",
    "\n",
    "def mine_association_rules(data, frequent_patterns, minconf):\n",
    "    association_rules_ls = []\n",
    "    for i_iter, frequent_pattern in enumerate(frequent_patterns):\n",
    "        print(f\"Processing  pattern {i_iter} out of {len(frequent_patterns)}\")\n",
    "        support = frequent_pattern[1]\n",
    "        freq_itemset = frequent_pattern[0]\n",
    "        if len(freq_itemset) > 1:\n",
    "            for antecedant in freq_itemset:\n",
    "                consequent_superset = [x for x in freq_itemset if x != antecedant]\n",
    "                for i_iter in range(1, len(consequent_superset)+1):\n",
    "                    consequent_ls = list(itertools.combinations(consequent_superset, i_iter))\n",
    "                    for consequent in consequent_ls:\n",
    "                        conf = calc_confidence(data, antecedant, consequent)\n",
    "                        if conf > minconf:\n",
    "                            association_rule = [antecedant] + list(consequent)\n",
    "                            flag = True  \n",
    "                            for x in association_rules_ls:\n",
    "                                if set(association_rule) == set(x[0]):\n",
    "                                    flag = False \n",
    "                                    break \n",
    "                            if flag == True: \n",
    "                                association_rules_ls.append([association_rule, support, conf])\n",
    "    return association_rules_ls \n",
    "\n",
    "minconf = 0.1\n",
    "association_rules_ls = mine_association_rules(train_df_key_value, frequent_patterns, minconf)\n",
    "print(f\"{association_rules_ls = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b529253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(600,): ((700,), 1.0), (700,): ((600,), 0.75)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with in-built python package\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, 0.1)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a078b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
